<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: Speech | Bill's Blog]]></title>
  <link href="http://ibillxia.github.io/blog/tags/speech/atom.xml" rel="self"/>
  <link href="http://ibillxia.github.io/"/>
  <updated>2014-05-04T18:33:44+08:00</updated>
  <id>http://ibillxia.github.io/</id>
  <author>
    <name><![CDATA[Bill Xia]]></name>
    <email><![CDATA[ibillxia@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[语音信号处理基础学习笔记之时域处理]]></title>
    <link href="http://ibillxia.github.io/blog/2013/05/08/speech-processing-in-time-domain/"/>
    <updated>2013-05-08T23:13:00+08:00</updated>
    <id>http://ibillxia.github.io/blog/2013/05/08/speech-processing-in-time-domain</id>
    <content type="html"><![CDATA[<p>语音信号的分析分为时域、频域、倒谱域等，时域分析简单、运算量小、物理意义明确，但对于语音识别而言，
更为有效的是频域的分析方法，那么为什么还有进行时域的分析呢？</p>




<p>语音信号具有时变特性，但在短时内可以看做是平稳的，所以语音的时域分析是建立在“短时”的条件下的，经研究统计，
语音信号在帧长为10ms~30ms内是相对平稳的。</p>




<p>语音信号是模拟信号，在进行处理之前，要进行数字化，模拟信号数字化的一般方法是采样，按照Nyquist采样定理进行
采样（一般在8K~10KHz）后，在进行量化（一般用8bit，也有16bit等）和编码，变为数字信号。</p>




<p>在语音信号数字化之后，就可以开始对其进行处理了，首先是预处理，由于语音信号的平均功率谱受声门激励和口鼻辐射的影响，
高频端大约在800Hz以上按6dB/倍频程跌落，为此要在预处理中进行预加重。预加重的目的是提升高频部分，是信号变得平坦，
以便于进行频谱分析或声道参数分析。预加重可以用具有6dB/倍频程的提升高频特性的预加重数字滤波器实现。预处理的另一
方面工作是分帧和加窗：分帧的帧长一般在10ms~30ms，分帧既可以是连续的，也可以是有部分over-lap；短时分析的实质是
对信号加窗，一般采用Hamming窗，其他的还有矩形窗、汉宁窗等，如下图所示。
<center><img src="/images/2013/IMAG2013050801.png"></center>
</p>




<!--more-->




<p>好了，经过预处理之后就可以真正开始进行时域分析了，这里的时域分析主要包含短时平均能量、短时过零分析、短时自相
关分析以及高阶统计量分析等。</p>




<p>短时平均能量（Short Time Average Energy）可以理解为先计算信号格采样值的平方，然后用一个移动窗h(n-m)选取出一个个
短时平方序列，并将各段的平方值求和，从而得到短时能量序列。短时平均能量（En）可以用来从清音中区分浊音（浊音的En比
清音大得多），可以用来确定声母和韵母、无声与有声、连字等的分界，还可以作为一种超音段信息用于语音识别。但短时平均
能量En对于高电平信号可能产生溢出，此时可以采用短时平均幅度（Short Time Average Magnitude）来度量语音信号幅度的变化。</p>




<p>信号的幅度值从正值到负值要经过零点，从负值到正值也要经过零点，称为过零，统计信号在单位时间（如1s）内过零的次数，
就成为过零率。如果信号按段分割，就成为短时，把各段信号的过零率做统计平均，就是短时平均过零率（Short Time Average Cross 
Zero Ratio）。短时平均过零率（Zn）可以作为“频率”来理解。过零率可以用来定量的分析清音/浊音，特别是在背景噪声电平较大时
更为有效（相比短时平均能量而言），有时还可以同时结合Zn和En来进行判定。</p>




<p>如果说短时平均过零率是描述复杂波形“频率”特征的一个参数，那么短时平均上升过零间隔（Short Time Rise Zero-Crossing Inteval）
就是描述复杂波形“周期”特性的参数。研究表明：在一定噪声背景下，该参数具有很好的稳健性，对不同的语音具有很好的差异性。</p>




<p>自相关函数是偶函数，语音信号的短时自相关函数（Short Time Autocorrelation Function）可以理解为序列[x(n)x(n-k)]通过一个
冲激响应为hk(n)的数字滤波器的输出，即有Rn(k) = [x(n)x(n-k)]*hk(n)。短时自相关函数是语音信号时域分析中的一个重要参量，但是
运算量很大。短时平均幅度差函数AMDF（Short Time Average Magnitude Difference Function）与自相关函数有类似的功效，但运算量
可降低许多，所以在语音信号处理中应用广泛。</p>




<p>最后是高阶统计量了。近来高阶统计量在语音信号处理中应用也越来越多，高阶统计量一般指高阶矩(Moment)、高阶累积量(Cumulant)以及
他们的谱——高阶矩谱和高阶累积量谱。首先定义了随机变量x的（第一）特征函数（也称为矩生成函数），实际为它的密度函数f(x)的傅里叶变换。
然后定义了第二特征函数（也称为累积量生成函数），它是第一特征函数的对数。还有随机变量x的k阶矩（mk）的定义，它是x的k次幂与f(x)的
乘积在x∈R上的积分。类似的还有k阶中心矩（μk）的定义，都与概率论中的定义差不多。现在，可以对第一、二特征函数进行泰勒展开，可以得
到ck（x的k阶累积量）和mk之间的一些关系，可以发现k<4时，ck=μk，此时ck的物理意义与μk的物理意义相同，而k>=4时，则不相等。对于c3，
描述了概率分布的对称性，通过定义一个新的概念——偏度（Skewness，也称为偏态系数）来衡量。对于c4，文中为了简化，假设了x的均值为0，
然后定义了一个称为峰态（也称峰度，Kurtosis）的概念，以表示分布相对于正太分布的尖锐或平坦程度。后面两小节分别对此进行了从单个
随机变量到多个随机变量的推广的分析和随机变量服从高斯分布（正态分布）的特殊情形做了分析。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深度学习及其在语音方面的应用]]></title>
    <link href="http://ibillxia.github.io/blog/2013/04/17/Deep-Learning-and-its-application-in-audio-and-speech-processing/"/>
    <updated>2013-04-17T22:43:00+08:00</updated>
    <id>http://ibillxia.github.io/blog/2013/04/17/Deep-Learning-and-its-application-in-audio-and-speech-processing</id>
    <content type="html"><![CDATA[<p>以下是今天在组会上讲的内容，与大家分享一下。有些地方我也没有完全理解，欢迎大家一起来讨论。</p>


<p><center>
<embed width="780"
    height="574"
    name="plugin"
    src="http://ibillxia.github.io/upload/Deep Learning - Bill Xia.pdf"
    type="application/pdf"
/>
</center></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MFCC参数提取及Matalab实现]]></title>
    <link href="http://ibillxia.github.io/blog/2012/07/18/MFCC-feature-extraction/"/>
    <updated>2012-07-18T20:10:00+08:00</updated>
    <id>http://ibillxia.github.io/blog/2012/07/18/MFCC-feature-extraction</id>
    <content type="html"><![CDATA[<h2>1.概述</h2>


<p>Mel倒谱系数（Mel-frequency cepstral coefficients，MFCC）是受人的听觉系统研究成果推动而导出的声学特征。
研究发现，当两个音调的频率差小于临界带宽时，人就会把两个音调听成一个(屏蔽效应)。Mel刻度是对这一临界带宽的
度量方法之一, MFCC在语音识别领域应用广泛。本文详细介绍了Mel频率倒谱系数参数的6大提取步骤。</p>




<h2>2.什么是Mel频率倒谱系数？</h2>


<p>Mel频率倒谱系数（Mel Frequency Cepstrum Coefficient）的缩写是MFCC，Mel频率是基于人耳听觉特性提出来的，
它与Hz频率成非线性对应关系。Mel频率倒谱系数(MFCC)则是利用它们之间的这种关系，计算得到的Hz频谱特征。</p>




<p>用录音设备录制一段模拟语音信号后，经由自定的取样频率(如8000 Hz、16000 Hz等)采样后转换(A/D)为数字语音信号。
由于在时域(time domain)上语音信号的波形变化相当快速、不易观察，因此一般都会在频域(frequency domain)上来观察，
其频谱是随着时间而缓慢变化的，因此通常可以假设在一较短时间中，其语音信号的特性是稳定的，通常我们定义这个较短
时间为一帧(frame)，根据人的语音的音调周期值的变化，一般取10~20ms。</p>




<!-- more -->


<h2>3.Mel频率倒谱系数(MFCC)参数的提取步骤</h2>


<h4>(1) 预加重(pre-emphasis)</h4>


<p>将经采样后的数字语音信号s(n)通过一个高通滤波器(high pass filter)：</br>
<center>$H(z)= 1 – a*z -1 , 0.9 < a < 1.0$. </center></br>
其中a一般取0.95左右。经过预加重后的信号为：</br>
<center>$s (n)= s(n)– a×s(n-1)$.</center></br>
因为发声过程中声带和嘴唇的效应，使得高频共振峰的振幅低于低频共振峰的振幅，进行预加重的目的就是为了消除声带和
嘴唇的效应，来补偿语音信号的高频部分。</p>

<h4>(2) 分帧(frame blocking)</h4>
<p>一般取10-30ms为一帧，为了避免窗边界对信号的遗漏，因此对帧做偏移时候，要有帧迭(帧与帧之间需要重叠一部分)。
一般取帧长的一半作为帧移，也就是每次位移一帧的二分之一后再取下一帧，这样可以避免帧与帧之间的特性变化太大。</p>

<h4>(3) 计算短时能量(energy)</h4>
<p>短时能量代表着音量的高低，亦即声音振幅的大小，可以根据此能量的值来过滤掉语音信号中的一些细微噪声。当一帧的能量
值低于我们定的门槛值(threshold)时，则将此帧作为静音段(silence)。</p>

<h4>(4) 加窗(hamming window)</h4>
<p>语音在长范围内是不停变动的，没有固定的特性无法做处理，所以将每一帧代入窗函数，窗外的值设定为0，其目的是消除各个
帧两端可能会造成的信号不连续性。常用的窗函数有方窗、汉明窗和汉宁窗等，根据窗函数的频域特性，常采用汉明窗。公式是在
加窗范围内，$w(i)=0.54-0.46*cos(2* \pi * \frac{i}{n-1}), i \in [0,n-1]$。</p>

<h4>(5) 快速傅立叶变换(FFT transform)</h4>
<p>由于语音信号在时域上的变化快速而不稳定，所以通常都将它转换到频域上来观察，此时它的频谱会随着时间作缓慢的变化。
所以通常将加窗后的帧经过FFT (Fast Fourier Transform)求出每帧的频谱参数。</p>

<h4>(6) 三角形带通滤波器(triangular band-pass filter)</h4>
<p>将每帧的频谱参数通过一组N个三角形带通滤波器(N一般为20~30个)所组成的梅尔刻度滤波器，将每个频带的输出取对数，求出每一个
输出的对数能量(log energy)，k = 1,2,… N。 再将此N个参数进行余弦变换(cosine transform)求出L阶的Mel-scale cepstrum参数。</p>

<h2>4.Matlab程序实现</h2>
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>function r = mfcc(s, fs)
</span><span class='line'>% MFCC参数提取
</span><span class='line'>% Reference: 论文《MFCC和LPCC特征参数在说话人识别中的研究》
</span><span class='line'>%
</span><span class='line'>% Inputs: s  contains the signal to analize
</span><span class='line'>%         fs is the sampling rate of the signal
</span><span class='line'>%
</span><span class='line'>% Output: r contains the transformed signal
</span><span class='line'>%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</span><span class='line'>m = 256;  % 帧长
</span><span class='line'>n = 100;  % 帧移
</span><span class='line'>l = length(s);  % 信号总长度
</span><span class='line'>nbFrame = floor((l - n) / m) + 1;  % 信号总帧数
</span><span class='line'>for i = 1:n
</span><span class='line'>for j = 1:nbFrame
</span><span class='line'>M(i, j) = s(((j - 1) * m) + i);  % 分帧
</span><span class='line'>end
</span><span class='line'>end
</span><span class='line'>h = hamming(n);  % Hamming窗w = 0.54 - 0.46*cos(2*pi*x);
</span><span class='line'>M2 = diag(h) * M;  % 对M加窗，形成对角矩阵M2
</span><span class='line'>for i = 1:nbFrame
</span><span class='line'>frame(:,i) = fft(M2(:, i));   % 进行快速傅里叶变换，将其转换到频域上
</span><span class='line'>end
</span><span class='line'>t = n / 2;
</span><span class='line'>% tmax = l / fs;
</span><span class='line'>m = melfb(20, n, fs);  % 调用20阶MEL滤波器组进行滤波
</span><span class='line'>n2 = 1 + floor(t);
</span><span class='line'>z = m * abs(frame(1:n2, :  )).^2;  % 取前n2行帧列向量的平方
</span><span class='line'>r = dct(log(z));  % 取对数后进行反余弦变换
</span><span class='line'>%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</span><span class='line'>function m = melfb(p, n, fs)
</span><span class='line'>% MELFB  Determine matrix for a mel-spaced filterbank
</span><span class='line'>%
</span><span class='line'>% Inputs:       p   number of filters in filterbank
</span><span class='line'>%               n   length of fft
</span><span class='line'>%               fs  sample rate in Hz
</span><span class='line'>%
</span><span class='line'>% Outputs:      x   a (sparse) matrix containing the filterbank amplitudes
</span><span class='line'>%                   size(x) = [p, 1+floor(n/2)]
</span><span class='line'>%
</span><span class='line'>% Usage:        For example, to compute the mel-scale spectrum of a
</span><span class='line'>%               colum-vector signal s, with length n and sample rate fs:
</span><span class='line'>%               f = fft(s);
</span><span class='line'>%               m = melfb(p, n, fs);
</span><span class='line'>%               n2 = 1 + floor(n/2);
</span><span class='line'>%               z = m * abs(f(1:n2)).^2;
</span><span class='line'>%
</span><span class='line'>%               z would contain p samples of the desired mel-scale spectrum
</span><span class='line'>%
</span><span class='line'>%               To plot filterbanks e.g.:
</span><span class='line'>%               plot(linspace(0, (12500/2), 129), melfb(20, 256, 12500)'),
</span><span class='line'>%               title('Mel-spaced filterbank'), xlabel('Frequency (Hz)');
</span><span class='line'>%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
</span><span class='line'>f0 = 700 / fs;
</span><span class='line'>fn2 = floor(n/2);
</span><span class='line'>lr = log(1 + 0.5/f0) / (p+1);
</span><span class='line'>% convert to fft bin numbers with 0 for DC term
</span><span class='line'>bl = n * (f0 * (exp([0 1 p p+1] * lr) - 1));
</span><span class='line'>b1 = floor(bl(1)) + 1;
</span><span class='line'>b2 = ceil(bl(2));
</span><span class='line'>b3 = floor(bl(3));
</span><span class='line'>b4 = min(fn2, ceil(bl(4))) - 1;
</span><span class='line'>pf = log(1 + (b1:b4)/n/f0) / lr;
</span><span class='line'>fp = floor(pf);
</span><span class='line'>pm = pf - fp;
</span><span class='line'>r = [fp(b2:b4) 1+fp(1:b3)];
</span><span class='line'>c = [b2:b4 1:b3] + 1;
</span><span class='line'>v = 2 * [1-pm(b2:b4) pm(1:b3)];
</span><span class='line'>m = sparse(r, c, v, p, 1+fn2);</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2>参考文献</h2>
<p>[1] <a href="http://www.semxi.com/TechnologyDetail.aspx?nID=27">http://www.semxi.com/TechnologyDetail.aspx?nID=27</a> </br>
[2] MFCC和LPCC特征参数在说话人识别中的研究</p>

]]></content>
  </entry>
  
</feed>