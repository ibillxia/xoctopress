<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: BPNN | Bill's Blog]]></title>
  <link href="http://ibillxia.github.com/blog/tags/bpnn/atom.xml" rel="self"/>
  <link href="http://ibillxia.github.com/"/>
  <updated>2013-10-22T22:35:17+08:00</updated>
  <id>http://ibillxia.github.com/</id>
  <author>
    <name><![CDATA[Bill Xia]]></name>
    <email><![CDATA[ibillxia@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[反向传播(BP)神经网络]]></title>
    <link href="http://ibillxia.github.com/blog/2013/03/30/back-propagation-neural-networks/"/>
    <updated>2013-03-30T21:37:00+08:00</updated>
    <id>http://ibillxia.github.com/blog/2013/03/30/back-propagation-neural-networks</id>
    <content type="html"><![CDATA[<p>前面几篇文章中对神经网络和深度学习进行一些简介，包括神经网络的发展历史、基本概念和常见的几种神经网络以及神经网络的学习方法等，
本文具体来介绍一下一种非常常见的神经网络模型——反向传播(Back Propagation)神经网络。</p>




<h2>1.概述</h2>


<p>BP（Back Propagation）神经网络是1986年由Rumelhart和McCelland为首的科研小组提出，参见他们发表在Nature上的论文
<em><a href="http://www.cs.toronto.edu/~hinton/absps/naturebp.pdf">Learning representations by back-propagating errors</a></em>
值得一提的是，该文的第三作者Geoffrey E. Hinton就是在深度学习邻域率先取得突破的神犇。
</p>




<p>BP神经网络是一种按误差逆传播算法训练的多层前馈网络，是目前应用最广泛的神经网络模型之一。BP网络能学习和存贮大量的
输入-输出模式映射关系，而无需事前揭示描述这种映射关系的数学方程。它的学习规则是使用最速下降法，通过反向传播来不断
调整网络的权值和阈值，使网络的误差平方和最小。</p>




<!-- more -->




<h2>2.BP网络模型</h2>


<p>一个典型的BP神经网络模型如图1所示。</br>
<center><img src="/images/2013/IMAG2013033001.jpg"></center>
<center>图1 典型的BP神经网络模型</center></p>




<p>BP神经网络与其他神经网络模型类似，不同的是，BP神经元的传输函数为非线性函数(而在感知机中为阶跃函数，在线性神经网络中为线性函数)，最常用的
是log-sigmoid函数或tan-sigmoid函数。BP神经网络(BPNN)一般为多层神经网络，图1中所示的BP神经网络的隐层的传输函数即为非线性函数，隐层可以有多层，
而输出层的传输函数为线性函数，当然也可以是非线性函数，只不过线性函数的输出结果取值范围较大，而非线性函数则限制在较小范围（如logsig函数输出
取值在(0,1)区间）。图1所示的神经网络的输入输出关系如下：</br>
1)输入层与隐层的关系：</br>
<center>$\boldsymbol{h} = \mathit{f_{1}} (\boldsymbol{W^{(1)}x}+\boldsymbol{b^{(1)}})$.</center>
其中$\boldsymbol{x}$为$m$维特征向量(列向量)，$\boldsymbol{W^{(1)}}$为$n × m$维权值矩阵，$\boldsymbol{b^{(1)}}$为$n$维的偏置(bias)向量(列向量)。</br>
2)隐层与输出层的关系：</br>
<center>$\boldsymbol{y} = \mathit{f_{2}} (\boldsymbol{W^{(2)}h}+\boldsymbol{b^{(2)}})$.</center>
</p>




<h2>3.BP网络的学习方法</h2>


<p>神经网络的关键之一是权值的确定，也即神经网络的学习，下面主要讨论一下BP神经网络的学习方法，它是一种监督学习的方法。</br>
假定我们有$q$个带label的样本(即输入)$p_{1},p_{2},...,p_{q}$，对应的label(即期望输出Target)为$T_{1},T_{2},...,T_{q}$，神经网络的实际输出
为$a2_{1},a2_{2},...,a2_{q}$，隐层的输出为$a1[.]$那么可以定义误差函数：</br>
<center>$\boldsymbol{E(W,B)} = \frac{1}{2}\sum_{k=1}^{n}(t_{k} - a2_{k})^{2} $.</center>
BP算法的目标是使得实际输出approximate期望输出，即使得训练误差最小化。BP算法利用梯度下降(Gradient Descent)法来求权值的变化及
误差的反向传播。对于图1中的BP神经网络，我们首先计算输出层的权值的变化量，从第$i$个输入到第$k$个输出的权值改变为：</br>
<center>$\Delta w2_{ki} = - \eta \frac{\partial E}{\partial w2_{ki}} \\
= - \eta \frac{\partial E}{\partial a2_{k}} \frac{\partial a2_{k}}{\partial w2_{ki}} \\
= \eta (t_{k}-a2_{k})f_{2}'a1_{i} = \eta \delta_{ki}a1_{i}$.</center>
其中$\eta$为学习速率。同理可得：</br>
<center>$\Delta b2_{ki} = - \eta \frac{\partial E}{\partial b2_{ki}} 
= - \eta \frac{\partial E}{\partial a2_{k}} \frac{\partial a2_{k}}{\partial b2_{ki}}
= \eta (t_{k}-a2_{k})f_{2}' = \eta \delta_{ki}$.</center>
而隐层的权值变化为：</br>
<center>$\Delta w1_{ij} = - \eta \frac{\partial E}{\partial w1_{ij}} 
= - \eta \frac{\partial E}{\partial a2_{k}} \frac{\partial a2_{k}}{\partial a1_{i}} \frac{\partial a1_{i}}{\partial w1_{ij}}
= \eta \sum_{k=1}^{n}(t_{k}-a2_{k})f_{2}'w2_{ki}f_{1}'p_{j} = \eta \delta_{ij}p_{j}$.</center>
其中，$\delta_{ij} = e_{i}f_{1}', e_{i} = \sum_{k=1}^{n}\delta_{ki}w2_{ki}$</br>
同理可得，$\Delta b1_{i} = \eta \delta_{ij}$。</br>
这里我们注意到，输出层的误差为$e_{j},j=1..n$，隐层的误差为$e_{i},i=1..m$，其中$e_{i}$可以认为是$e_{j}$的加权组合，由于作用函数的
存在，$e_{j}$的等效作用为$\delta_{ji} = e_{j}f'()$。
</p>




<h2>4.BP网络的设计</h2>


<p>在进行BP网络的设计是，一般应从网络的层数、每层中的神经元个数和激活函数、初始值以及学习速率等几个方面来进行考虑，下面是一些选取的原则。</p>




<p><strong>1.网络的层数</strong></br>
理论已经证明，具有偏差和至少一个S型隐层加上一个线性输出层的网络，能够逼近任何有理函数，增加层数可以进一步降低误差，提高精度，但同时也是网络
复杂化。另外不能用仅具有非线性激活函数的单层网络来解决问题，因为能用单层网络解决的问题，用自适应线性网络也一定能解决，而且自适应线性网络的
运算速度更快，而对于只能用非线性函数解决的问题，单层精度又不够高，也只有增加层数才能达到期望的结果。
</p>




<p><strong>2.隐层神经元的个数</strong></br>
网络训练精度的提高，可以通过采用一个隐含层，而增加其神经元个数的方法来获得，这在结构实现上要比增加网络层数简单得多。一般而言，我们用精度和
训练网络的时间来恒量一个神经网络设计的好坏：</br>
（1）神经元数太少时，网络不能很好的学习，训练迭代的次数也比较多，训练精度也不高。</br>
（2）神经元数太多时，网络的功能越强大，精确度也更高，训练迭代的次数也大，可能会出现过拟合(over fitting)现象。</br>
由此，我们得到神经网络隐层神经元个数的选取原则是：在能够解决问题的前提下，再加上一两个神经元，以加快误差下降速度即可。
</p>




<p><strong>3.初始权值的选取</strong></br>
一般初始权值是取值在$(-1,1)$之间的随机数。另外威得罗等人在分析了两层网络是如何对一个函数进行训练后，提出选择初始权值量级为$\sqrt[r]{s}$的策略，
其中$r$为输入个数，$s$为第一层神经元个数。
</p>




<p><strong>4.学习速率</strong></br>
学习速率一般选取为$0.01 - 0.8$，大的学习速率可能导致系统的不稳定，但小的学习速率导致收敛太慢，需要较长的训练时间。对于较复杂的网络，
在误差曲面的不同位置可能需要不同的学习速率，为了减少寻找学习速率的训练次数及时间，比较合适的方法是采用变化的自适应学习速率，使网络在
不同的阶段设置不同大小的学习速率。
</p>




<p><strong>5.期望误差的选取</strong></br>
在设计网络的过程中，期望误差值也应当通过对比训练后确定一个合适的值，这个合适的值是相对于所需要的隐层节点数来确定的。一般情况下，可以同时对两个不同
的期望误差值的网络进行训练，最后通过综合因素来确定其中一个网络。
</p>




<h2>5.BP网络的局限性</h2>


<p>BP网络具有以下的几个问题：</br>
<strong>(1)需要较长的训练时间</strong>：这主要是由于学习速率太小所造成的，可采用变化的或自适应的学习速率来加以改进。</br>
<strong>(2)完全不能训练</strong>：这主要表现在网络的麻痹上，通常为了避免这种情况的产生，一是选取较小的初始权值，而是采用较小的学习速率。</br>
<strong>(3)局部最小值</strong>：这里采用的梯度下降法可能收敛到局部最小值，采用多层网络或较多的神经元，有可能得到更好的结果。
</p>




<h2>6.BP网络的改进</h2>


<p>BP算法改进的主要目标是加快训练速度，避免陷入局部极小值等，常见的改进方法有带动量因子算法、自适应学习速率、变化的学习速率以及作用函数后缩法等。
动量因子法的基本思想是在反向传播的基础上，在每一个权值的变化上加上一项正比于前次权值变化的值，并根据反向传播法来产生新的权值变化。而自适应学习
速率的方法则是针对一些特定的问题的。改变学习速率的方法的原则是，若连续几次迭代中，若目标函数对某个权倒数的符号相同，则这个权的学习速率增加，
反之若符号相反则减小它的学习速率。而作用函数后缩法则是将作用函数进行平移，即加上一个常数。</p>




<h2>7.BP网络实现异或</h2>


<p>见参考文献[7]或Andrew Ng. 的ML公开课的第8讲。</p>


<p>另外BP算法的讲解及C++实现参见[4]。</p>




<h2>参考文献</h2>


<p>[1]An Introduction to Back-Propagation Neural Networks: http://www.seattlerobotics.org/encoder/nov98/neural.html</br>
[2]Wiki - Backpropagation: http://en.wikipedia.org/wiki/Backpropagation</br>
[3]Chapter 7 The backpropagation algorithm of Neural Networks - A Systematic Introduction by Raúl Rojas: http://page.mi.fu-berlin.de/rojas/neural/chapter/K7.pdf</br>
[4]Back-propagation Neural Net - C++ 实现: http://www.codeproject.com/Articles/13582/Back-propagation-Neural-Net</br>
[5]《Visual C++数字图像模式识别技术及工程实践》(第3章)，求实科技 张宏林</br>
[6]《Matlab神经网络设置及应用》(第5章)，周品，清华大学出版社
</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[神经网络模型分类]]></title>
    <link href="http://ibillxia.github.com/blog/2013/03/24/classes-of-neural-networks/"/>
    <updated>2013-03-24T23:07:00+08:00</updated>
    <id>http://ibillxia.github.com/blog/2013/03/24/classes-of-neural-networks</id>
    <content type="html"><![CDATA[<p>本文主要介绍一下几种不同类型的神经网络模型，主要有前馈神经网络，反馈神经网络，自组织神经网络，随机神经网络</p>




<h2>1.前馈神经网络</h2>


<h4>1)自适应线性神经网络(Adaline)</h4>


<p>自适应线性神经网络（Adaptive Linear，简称Adaline) 是由威德罗（Widrow）和霍夫（Hoff）首先提出的。它与感知器的主要不同之处在于
其神经元有一个线性激活函数，这允许输出可以是任意值，而不仅仅只是像感知器中那样只能取0或1。它采用的是W—H学习法则，也称最小均方差(LMS)
规则对权值进行训练。自适应线性元件的主要用途是线性逼近一个函数式而进行模式联想。</p>




<h4>2)单层感知器</h4>


<p>单层感知器（Perceptron）是由美国计算机科学家罗森布拉特（F.Roseblatt）于1957年提出的。它是一个具有单层神经元的网络，由线性阈值
逻辑单元所组成。它的输入可以是非离散量，而且可以通过学习而得到，这使单层感知器在神经网络研究中有着重要的意义和地位：它提出了自组织、
自学习的思想，对能够解决的问题，有一个收敛的算法，并从数学上给出了严格的证明。</p>


<!-- more -->




<h4>3)多层感知器</h4>


<p>单层感知器由于只有一个神经元，功能单一，只能完成线性决策或实现“与”、“或”、“非”等单一逻辑函数。多层感知器（Multilayer Perceptron）
是在单层感知器的基础上发展起来的，它是一种在输入层与输出层之间含有一层或多层隐含结点的具有正向传播机制的神经网络模型。多层感知器克服了
单层感知器的许多局限，它的性能主要来源于它的每层结点的非线性特性（节点输出函数的非线性特性）。如果每个结点是线性的，那么多层感知器的
功能就和单层感知器一样。</p>




<p>在人工神经网络中，应用最普遍的是多层前馈网络模型。在1986年，Rumelhant和McClelland提出了多层前馈网络的误差反向传播（Error Back Propagation）
学习算法，简称BP算法，这是一种多层网络的逆推学习算法。由此采用BP算法的多层前馈网络也广泛被称为BP网络。</p>




<h2>2.反馈神经网络</h2>


<p>反馈神经网络模型可用一完备的无向图表示。从系统的观点看，反馈神经网络模型是一反馈动力学系统，它具有极复杂的动力学特性。在反馈神经网络模型中，
我们关心的是其稳定性，稳定性是神经网络相联存储性质的体现，可以说稳定就意味着完成回忆。从计算的角度讲，反馈神经网络模型具有比前馈神经网络模型
更强的计算能力，它包括Hopfield神经网络、海明神经网络和双向联想存储器。</p>




<h4>1)Hopfield神经网络</h4>


<p>1982年，美国神经网络学者霍普菲尔德（J.J.Hopfield）提出了反馈型的全连接神经网络，是一种对记忆功能的较好模拟。Hopfield神经网络的结构特点是：
每一个神经元的输出信号通过其它神经元后，反馈到自己的输入端。这种反馈方式有利于通过联想记忆实现最优化，经过分析比较与判断确定最优解决问题的方法。
网络状态的演变是一种非线性动力学系统的行为描述过程，作为一种非线性动力学系统，系统从初始化出发后，系统状态经过演变可能发生如下结果： </br>
a) 渐进稳定形成稳定点，又称为吸引子。</br>
b) 极限环状态。</br>
c) 混沌状态。</br>
d) 发散状态。</br>
发散状态是不希望看到的。对于人工神经网络而言，由于选取网络的变换函数为一个有界函数，因此系统状态不会演变成发散。</p>




<h4>2)海明神经网络(Hamming)</h4>


<p>海明（Hamming）网络由匹配子网和竞争子网组成。匹配子网在学习阶段将若干类别的样本记忆存储在网络的连接权值中；在工作阶段（回忆阶段），
该子网计算输入模式和各个样本模式的匹配程度，并将结果送入竞争子网中，由竞争子网选择出匹配子网中最大的输出。从而，实现了对离散输入模式
进行在海明距离最小意义下的识别和分类。</p>




<h4>3)双向联想存储器(BAM)</h4>


<p>双向联想存储器（BAM）是由日本的Kosko提出的一种神经网络模型，它是ART网络模型的一种简化形式， 是一种异联想存储器。它能存储成对的
模式$(A1，B1)， (A2 ,B2), ⋯,( AN, BN)$。Ai和Bi是不同向量空间中的向量。如果模式A输入到BAM，输出是模式B，且若A与iA最为接近，B就是在BAM所
存储的向量iB。 BAM网络模型中的神经元为非线性单元，每个神经元的作用相当于一个非线性函数，这个函数一般取为S型函数：$y = \frac{1}{1+exp^{-x}}$.
</p>




<h2>3.自组织神经网络</h2>


<h4>1)自适应谐振理论(ART)</h4>


<p>自适应谐振理论（adaptive resonance theory，简称ART）的目的是为人类的心理和认知活动建立一个统一的数学理论。1976年，美国学者Carpenter
和Grossberg提出了ART神经网络模型。它是利用生物神经细胞的自兴奋与侧抑制的原理来指导学习，让输入模式通过网络的双向连接权的作用来进行比较
与识别，最后使网络对输入模式产生所谓的谐振，因此来完成对输入模式的记忆，并以同样的方式实现网络的回想。当网络已经存储了一定的内容之后，
则可用它来进行识别。在识别过程中，如果输入是已记忆的或与已记忆的模式十分相似，则网络会把它回想出来。如果是没有记忆的新模式，则在不影响
原有记忆的前提下，把它记忆下来，并用一个没用过的输出层神经元作为这一新模式的分类标志。<p>

<p>ART网络主要有三种形式：ART1是处理双极型或二进制数据，即观察向量的每个分量是二值的，只能取0或1；ART2是用于处理连续型模拟信号，
即观察向量的每个分量可取任意实数值，也可用于二进制输入；ART3是分级搜索模型，它兼容前两种结构的功能并将两层神经元网络扩大为任意
多层神经元网络，并在神经元的运行模型中纳入人类神经元生物电—化学反应机制，因而具备了相当强的功能和扩展能力。</p>

<h4>2)自组织映射神经网络模型(SOM)</h4>
<p>在人的感觉通道上一个很重要的组织原理是神经元有序地排列着，并且往往可以反映出所感觉到外界刺激的某些物理特性。如在听觉通道的每一个层次上，
其神经元与神经纤维在结构上的排列与外界刺激的频率关系十分密切，对于某个频率，相应的神经元具有最大的响应，这种听觉通道上的有序排列一直延续到
听觉皮层，尽管许多低层次上的组织是预先排好的，但高层次上的神经组织则是通过学习自组织而形成的。由此生物背景，提出了自组织映射神经网络模型（SOM）。</p>

<h4>3)对流神经网络模型(CPN)</h4>
<p>CPN是由SOM模型和Grossberg外星网络组合而形成的一种神经网络模型。是由美国Hecht-Nielsen和Robert-Nielsen于1987年首先提出来的。一般认为，
这种由两种或多种网络组合而成的新型网络往往具有比原网络模型更强的能力，它能够克服单个网络的缺陷，而且学习时间较短。</p>

<h2>4.随机神经网络</h2>
<h4>1) 模拟退火算法</h4>
<p>在物理学中，对固体物质进行退火处理时，通常先将它加温溶化，使其中的粒子可自由地运动，然后随着物质温度的下降，粒子也形成了低能态的晶格。
若在凝结点附近的温度下降速度足够慢，则固体物质一定会形成最低能量的基态。对于组合优化问题来说，它也有类似的过程，也就是说物理中固体物质的
退火过程与组合优化问题具有相似性。组合优化问题也是在解空间寻求花费函数最小（或最大）的解。</p>

<h4>2) Boltzmann机</h4>
<p>Boltzmann机是由Hinton和Sejnowski提出来的一种统计神经网络模型，是在Hopfield网络基础之上引入了随机性机制而形成的。与Hopfield神经网络不同
的是Boltzmann机具有学习能力，即其权值通过学习来调整，而不是预先设置。Boltzmann机是一种约束满足神经网络模型。</p>

<p>基于模拟退火算法的波尔兹曼机训练的基本思想为：当神经网络中某个与温度对应的参数发生变化时，神经网络的兴奋模式也会如同物理上的热运动那
样发生变化：当温度逐渐下降时，由决定函数判断神经元是否处于兴奋状态。在从高温到低温的退火(annealing)中，能量并不会停留在局部极小值上，
而以最大的概率到达全局最小值。</p>

<h3>推荐资料</h3>
<p>Machine Learning Lecture by Andrew Ng, Stanford University</br>
Lecture VIII: Neural Network - Representation</br>
Lecture IX: Neural Network - Learning</br>
Video courses on Coursera: https://class.coursera.org/ml-2012-002/lecture/index</br>
Lecture homepage in Standford: http://cs229.stanford.edu/</p>

<h3>参考文献</h3>
<p>[1] Simon Haykin, “Neural Networks: a Comprehensive Foundation”, 2009 (3rd edition)</br>
[2]T-61.3030 <a href="http://www.cis.hut.fi/Opinnot/T-61.3030/schedule2007.shtml">PRINCIPLES OF NEURAL COMPUTING</a> (5 CP)</br>
[3]人工神经网络综述：<a href="http://ishare.iask.sina.com.cn/f/36537774.html">http://ishare.iask.sina.com.cn/f/36537774.html</a></br>
</p>

]]></content>
  </entry>
  
</feed>
