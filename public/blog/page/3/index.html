
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Bill's Blog</title>
  <meta name="author" content="Bill Xia">

  
  <meta name="description" content="Yesterday is History, Tomorrow a Mystery, Today is a Gift, Thats why it's called the Present！">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://ibillxia.github.io/blog/page/3">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/bootstrap/bootstrap.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/bootstrap/responsive.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/syntax/syntax.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/style.css" media="screen, projection" rel="stylesheet" type="text/css">
  <style type="text/css">
    body {
      padding-bottom: 40px;
    }
    h1 {
      margin-bottom: 15px;
    }
    img {
      max-width: 100%;
    }
    .sharing, .meta, .pager {
      margin: 20px 0px 20px 0px;
    }
    .page-footer p {
      text-align: center;
    }
  </style>
  <script src="/javascripts/libs/jquery.js"></script>
  <script src="/javascripts/libs/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/bootstrap.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Bill's Blog" type="application/atom+xml">
  <script type="text/javascript">
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}

$(document).bind('DOMNodeInserted', function(event) {
  addBlankTargetForLinks();
});
</script>
<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<script type="text/javascript">
$(document).ready(function(){

	// hide #back-top first
	$("#back-top").hide();
	
	// fade in #back-top
	$(function () {
		$(window).scroll(function () {
			if ($(this).scrollTop() > 100) {
				$('#back-top').fadeIn();
			} else {
				$('#back-top').fadeOut();
			}
		});

		// scroll body to 0px on click
		$('#back-top a').click(function () {
			$('body,html').animate({
				scrollTop: 0
			}, 800);
			return false;
		});
	});

});
</script>


  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-39460228-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <nav role="navigation"><div class="navbar navbar-inverse">
  <div class="navbar-inner">
    <div class="container">
      <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </a>

      <a class="brand" href="/">Bill's Blog</a>

      <div class="nav-collapse">
        <ul class="nav">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/blog/tags">Tags</a></li>
  <li><a href="/about">About</a></li>
</ul>


        <ul class="nav pull-right" data-subscription="rss">
          <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
          
        </ul>

        
          <form class="pull-right navbar-search" action="http://www.google.com/" method="get">
            <fieldset role="search">
              <input type="hidden" name="q" value="site:ibillxia.github.io" />
              <input class="search-query" type="text" name="q" results="0" placeholder="Search"/>
            </fieldset>
          </form>
        
      </div>
    </div>
  </div>
</div>
</nav>
  <div class="container">
    <div class="row-fluid">
      <div class="span9">
  
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/15/audio-signal-processing-time-domain-ZeroCR-python-realization/">语音信号处理之时域分析-过零率及其Python实现</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-15T21:44:00+08:00" pubdate data-updated="true">May 15<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/05/15/audio-signal-processing-time-domain-ZeroCR-python-realization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>过零率（Zero Crossing Rate）</h2>


<p>概念：过零率（Zero Crossing Rate，ZCR）是指在每帧中，语音信号通过零点（从正变为负或从负变为正）的次数。
这个特征已在语音识别和音乐信息检索领域得到广泛使用，是对敲击的声音的分类的关键特征。</p>




<p>ZCR的数学形式化定义为：
<center>$zcr = \frac{1}{T-1}\sum_{t=1}^{T-1}\pi\{s_{t}s_{t-1}<0\}$.</center>
其中$s$是采样点的值，$T$为帧长，函数$\pi\{A\}$在A为真是值为1，否则为0.
</p>




<p>特性：</br>
(1).一般而言，清音（unvoiced sound）和环境噪音的ZCR都大于浊音（voiced sound）；</br>
(2).由于清音和环境噪音的ZCR大小相近，因而不能够通过ZCR来区分它们；</br>
(3).在实际当中，过零率经常与短时能量特性相结合来进行端点检测，尤其是ZCR用来检测清音的起止点；</br>
(4).有时也可以用ZCR来进行粗略的基频估算，但这是非常不可靠的，除非有后续的修正（refine）处理过程。
</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/15/audio-signal-processing-time-domain-ZeroCR-python-realization/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/15/audio-signal-process-time-domain-volume-python-realization/">语音信号处理之时域分析-音量及其Python实现</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-15T19:36:00+08:00" pubdate data-updated="true">May 15<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/05/15/audio-signal-process-time-domain-volume-python-realization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>1.概述（Introduction）</h2>


<p>本系列文主要介绍语音信号时域的4个基本特征及其Python实现，这4个基本特征是：</br>
(1)音量（Volume）；</br>
(2)过零率（Zero-Crossing-Rate）；</br>
(3)音高（Pitch）；</br>
(4)音色（Timbre）。
</p>




<h2>2.音量（Volume）</h2>


<p>音量代表声音的强度，可由一个窗口或一帧内信号振幅的大小来衡量，一般有两种度量方法：</br>
（1）每个帧的振幅的绝对值的总和：
<center>$volume = \sum_{i=1}^{n}|s_{i}|$.</center>
其中$s_{i}$为第该帧的$i$个采样点，$n$为该帧总的采样点数。这种度量方法的计算量小，但不太符合人的听觉感受。</br>
（2）幅值平方和的常数对数的10倍：
<center>$volume = 10 * log_{10}\sum_{i=1}^{n}s_{i}^{2}$.</center>
它的单位是分贝（Decibels），是一个对数强度值，比较符合人耳对声音大小的感觉，但计算量稍复杂。
</p>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/15/audio-signal-process-time-domain-volume-python-realization/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/08/speech-processing-in-time-domain/">语音信号处理基础学习笔记之时域处理</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-08T23:13:00+08:00" pubdate data-updated="true">May 8<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/05/08/speech-processing-in-time-domain/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>语音信号的分析分为时域、频域、倒谱域等，时域分析简单、运算量小、物理意义明确，但对于语音识别而言，
更为有效的是频域的分析方法，那么为什么还有进行时域的分析呢？</p>




<p>语音信号具有时变特性，但在短时内可以看做是平稳的，所以语音的时域分析是建立在“短时”的条件下的，经研究统计，
语音信号在帧长为10ms~30ms内是相对平稳的。</p>




<p>语音信号是模拟信号，在进行处理之前，要进行数字化，模拟信号数字化的一般方法是采样，按照Nyquist采样定理进行
采样（一般在8K~10KHz）后，在进行量化（一般用8bit，也有16bit等）和编码，变为数字信号。</p>




<p>在语音信号数字化之后，就可以开始对其进行处理了，首先是预处理，由于语音信号的平均功率谱受声门激励和口鼻辐射的影响，
高频端大约在800Hz以上按6dB/倍频程跌落，为此要在预处理中进行预加重。预加重的目的是提升高频部分，是信号变得平坦，
以便于进行频谱分析或声道参数分析。预加重可以用具有6dB/倍频程的提升高频特性的预加重数字滤波器实现。预处理的另一
方面工作是分帧和加窗：分帧的帧长一般在10ms~30ms，分帧既可以是连续的，也可以是有部分over-lap；短时分析的实质是
对信号加窗，一般采用Hamming窗，其他的还有矩形窗、汉宁窗等，如下图所示。
<center><img src="/images/2013/IMAG2013050801.png"></center>
</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/08/speech-processing-in-time-domain/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/05/01/go-hiking-International-Labour-Day/">五一登高远足</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-01T22:01:00+08:00" pubdate data-updated="true">May 1<span>st</span>, 2013</time>
        
         | <a href="/blog/2013/05/01/go-hiking-International-Labour-Day/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>五一天晴气爽，登高望远，强身健体！只可惜“不畏浮云遮望眼，只缘身在最高层” 这句诗在空气严重污染的今天已不适用了！</p>




<p><img src="/images/2013/IMAG2013050101.jpg">

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/05/01/go-hiking-International-Labour-Day/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/04/26/building-speaker-recognition-system-using-alize-etc/">使用Alize等工具构建说话人识别平台</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-26T22:07:00+08:00" pubdate data-updated="true">Apr 26<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/26/building-speaker-recognition-system-using-alize-etc/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>前段时间有好几位同学询问如何用Alize实现说话人识别的问题，由于寒假前赶Paper，来不及详细解答，更没时间写Demo。
开学后不久抽时间写了一个Demo，并上传到了GitHub：https://github.com/ibillxia/VoicePrintReco/tree/master/Demo</p>




<p>下面将利用Alize+SPro进行简单的GMM-Based的说话人识别的基本流程总结如下：</br>
1.Features extraction 特征提取</br>
sfbcep.exe（MFCC）或slpcep.exe（LPCC）</br>

2.Silence removal 静音检测和去除</br>
NormFeat.exe 先能量规整</br>
EnergyDetector.exe 基于能量检测的静音去除</br>

3.Features Normalization 特征规整</br>
NormFeat.exe 再使用这个工具进行特征规整</br>

4.World model training</br>
TrainWorld.exe 训练UBM</br>

5.Target model training</br>
TrainWorld.exe 在训练好UBM的基础上训练training set和testing set的GMM</br>

6.Testing</br>
ComputeTest.exe 将testing set 的GMM在training set的GMM上进行测试和打分</br>

7.Score Normalization</br>
ComputeNorm.exe 将得分进行规整</br>

8. Compute EER 计算等错误率</br>
你可以查查计算EER的matlab代码，NIST SRE的官网上有下载（http://www.itl.nist.gov/iad/mig//tools/DETware_v2.1.targz.htm）。</br>
</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/04/26/building-speaker-recognition-system-using-alize-etc/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/04/22/VALSE2013/">VALSE2013</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-22T22:28:00+08:00" pubdate data-updated="true">Apr 22<span>nd</span>, 2013</time>
        
         | <a href="/blog/2013/04/22/VALSE2013/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>学术研讨</h3>


<p>VALSE是Vision And Learning SEminar的缩写，它主要目的是为计算机视觉、图像处理、模式识别与机器学习研究领域内的中国青年学者（以70后研发
人员为主）提供一个深层次学术交流的舞台。虽然参与会议和做报告的人主要是做视觉的，但很多问题是机器学习和模式识别当中的一般性问题，所以我这
个搞语音的也去打酱油了^_^。</p>




<p>今年的VALSE在南京东南大学召开，参加会议的人数超出预期，会场爆满，仅学校的老师和公司的研究人员就占了会场大半，学生沦落到只能座最后两排，
或者座分会场（这个太不科学了-_-!）。会程安排也很紧凑，中午几乎没有休息时间，吃饭都很赶，而下午也很晚（6点半左右）才结束。这次会议有好几个
perfect的报告，但也有些不太感兴趣的，有的甚至感觉很2。除了一些报告，还有两个主题讨论会，印象中主要包括三个论题：学术界与工业界的Gap及衔接
问题，深度学习是否是计算机视觉的终极解决方案，计算机视觉要不要从生物视觉机理中受启发等。</p>




<p>闲话少说，言归正传，数萝卜下窖的讲讲这两天的经历吧。
第一天上午，第一个做报告的是MSRA的张磊，主要讲了计算机视觉的一些基本问题，从AI的历史将起，提到了Turing Test，是人工智能
的Benchmark。而CV的一个基本问题是Object Recognition，人们的研究经历了从之前的Model Based到如今的Data Driven及Big Data的过程，各种模型和方法可谓
层出不穷，然而对于真正解决问题、真正达到人类一般的视觉智能，还相差甚远。接着他讲了关于在路灯下找钥匙的故事（详询http://tongyanyan.blog.edu.cn/2006/427512.html），
听了这个故事后，感觉那个找钥匙的人很滑稽可笑，然而再想想我们自己正在做的研究，是不是在某种程度上和故事中的这个人一样呢。通过这个故事，他引出自己
的观点：要想解决Object Recognition这个问题或者说要解决CV的问题，就需要More Effective Representation & Match。接下来讲在Representation方面一些研究
人员提出的一些人工设计的Feature，而在Match方面则从Point、Line、Plane、Volume（点线面体）进行了详尽的讲述。最后还提了一下Deep Neural Network在CV中的
应用，可以discover hidden patterns。虽然对CV中的很多概念和模型方法不太了解，但感觉还是挺有收获的。</p>




<p>上午的后两个报告都是讲Sparse的，虽然之前看过关于Sparse Coding的东西，但当他们在上面讲的，主要偏重与Sparse这个问题的优化求解方法及其变形，
涉及到很多数学公式和推导，感觉很枯燥，加之晚睡早起，有点犯困，所以基本没有听进去。贾佳亚的报告还似懂非懂，而陈欢欢的Sparse Bayesian Learning
表示完全没听懂。个人感觉Sparse还是很重要的，所以在弄完Deep Learning这个专题后，我想有必要对这两个报告及其相关论文再做深入的学习和研究。</p>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/04/22/VALSE2013/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/04/17/Deep-Learning-and-its-application-in-audio-and-speech-processing/">深度学习及其在语音方面的应用</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-17T22:43:00+08:00" pubdate data-updated="true">Apr 17<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/17/Deep-Learning-and-its-application-in-audio-and-speech-processing/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>以下是今天在组会上讲的内容，与大家分享一下。有些地方我也没有完全理解，欢迎大家一起来讨论。</p>


<p><center>
<embed width="780"
    height="574"
    name="plugin"
    src="/upload/Deep Learning - Bill Xia.pdf"
    type="application/pdf"
/>
</center></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/04/12/Energy-Based-Models-and-Boltzmann-Machines/">基于能量的模型和波尔兹曼机</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-12T22:12:00+08:00" pubdate data-updated="true">Apr 12<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/12/Energy-Based-Models-and-Boltzmann-Machines/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>由于深度置信网络（Deep Belief Networks，DBN）是基于限制性玻尔兹曼机（Restricted Boltzmann Machines，RBM）的深层网络结构，
所以本文重点讨论一下玻尔兹曼机（BM），以及它的学习算法——对比散度（Contrastive Divergence，CD）算法。在介绍BM前，我们首先介绍一下
基于能量的模型（Energy Based Model，EBM），因为BM是一种特殊的EBM。</p>




<h2>1. 基于能量的模型(EBM)</h2>


<p>基于能量的模型是一种具有普适意义的模型，可以说它是一种模型框架，在它的框架下囊括传统的判别模型和生成模型，图变换网络(Graph-transformer 
Networks)，条件随机场，最大化边界马尔科夫网络以及一些流形学习的方法等。EBM通过对变量的每个配置施加一个有范围限制的能量来捕获变量之间的依赖
关系。EBM有两个主要的任务，一个是推断(Inference)，它主要是在给定观察变量的情况，找到使能量值最小的那些隐变量的配置；另一个是学习(Learning)，
它主要是寻找一个恰当的能量函数，使得观察变量的能量比隐变量的能量低。</p>




<p>基于能量的概率模型通过一个能量函数来定义概率分布，
<center>$p(x) = \frac{e^{E(x)}}{Z}.$ &#8230; ①</center>
其中Z为规整因子，
<center>$Z = \sum _{x} e^{-E(x)}.$ &#8230; ②</center>
基于能量的模型可以利用使用梯度下降或随机梯度下降的方法来学习，具体而言，就是以训练集的负对数作为损失函数，
<center>$l(\theta,D) = -L(\theta,D) = - \frac{1}{N}\sum_{x^{(i)}\in D} log p(x^{(i)}).$ &#8230; ③</center>
其中$\theta$为模型的参数，将损失函数对$\theta$求偏导，
<center>$\Delta = \frac{\partial l(\theta,D)}{\partial \theta} = - \frac{1}{N} \frac{\partial \sum log p(x^{(i)})}{\partial \theta}.$ &#8230; ④</center>
即得到损失函数下降最快的方向。</p>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/04/12/Energy-Based-Models-and-Boltzmann-Machines/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/04/10/Intel-Developer-Forum-2013-Nuance-Dragon-Presentation/">2013IDF声龙语音识别技术演示</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-10T12:57:00+08:00" pubdate data-updated="true">Apr 10<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/10/Intel-Developer-Forum-2013-Nuance-Dragon-Presentation/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>2013英特尔信息技术峰会(Intel Developer Forum, IDF)上，来自Nuance的声龙语音合成和识别技术的演示，中文语音识别不给力，
笑点频出啊，哈哈</p>




<p><iframe height=560 width=780 src="http://player.youku.com/embed/XNTQwNjQ0MjUy" frameborder=0 allowfullscreen></iframe></p>



</div>
  
  


    </article>
  
  
    <article>
      
  <header class="page-header">
    
      <h1 class="entry-title"><a href="/blog/2013/04/06/Convolutional-Neural-Networks/">卷积神经网络（CNN）</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-06T23:34:00+08:00" pubdate data-updated="true">Apr 6<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/06/Convolutional-Neural-Networks/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>1. 概述</h2>


<p>卷积神经网络是一种特殊的深层的神经网络模型，它的特殊性体现在两个方面，一方面它的神经元间的连接是<strong>非全连接</strong>的，
另一方面同一层中某些神经元之间的连接的<strong>权重是共享的</strong>（即相同的）。它的非全连接和权值共享的网络结构使之更类似于生物
神经网络，降低了网络模型的复杂度（对于很难学习的深层结构来说，这是非常重要的），减少了权值的数量。</p>




<p>卷积网络最初是受视觉神经机制的启发而设计的，是为识别二维形状而设计的一个多层感知器，这种网络结构对平移、比例缩放、倾斜或者共他
形式的变形具有高度不变性。1962年Hubel和Wiesel通过对猫视觉皮层细胞的研究，提出了感受野(receptive field)的概念，1984年日本学者Fukushima
基于感受野概念提出的神经认知机(neocognitron)模型，它可以看作是卷积神经网络的第一个实现网络，也是感受野概念在人工神经网络领域的首次应用。</p>




<p>神经认知机将一个视觉模式分解成许多子模式(特征)，然后进入分层递阶式相连的特征平面进行处理，它试图将视觉系统模型化，使其能够在即使物体有
位移或轻微变形的时候，也能完成识别。神经认知机能够利用位移恒定能力从激励模式中学习，并且可识别这些模式的变化形。在其后的应用研究中，Fukushima
将神经认知机主要用于手写数字的识别。随后，国内外的研究人员提出多种卷积神经网络形式，在邮政编码识别（Y. LeCun etc）、车牌识别和人脸识别等方面
得到了广泛的应用。</p>




<h2>2. CNN的结构</h2>


<p>卷积网络是为识别二维形状而特殊设计的一个多层感知器，这种网络结构对平移、比例缩放、倾斜或者共他形式的变形具有高度不变性。
这些良好的性能是网络在有监督方式下学会的，网络的结构主要有稀疏连接和权值共享两个特点，包括如下形式的约束：</br>
1 特征提取。每一个神经元从上一层的局部接受域得到突触输人，因而迫使它提取<strong>局部特征</strong>。一旦一个特征被提取出来，
只要它相对于其他特征的位置被近似地保留下来，它的精确位置就变得没有那么重要了。</br>
2 特征映射。网络的每一个计算层都是由<strong>多个特征映射组</strong>成的，每个特征映射都是平面形式的。平面中单独的神经元在约束下<strong>共享
相同的突触权值</strong>集，这种结构形式具有如下的有益效果：a.平移不变性。b.自由参数数量的缩减(通过权值共享实现)。</br>
3.子抽样。每个卷积层跟着一个实现局部平均和子抽样的计算层，由此特征映射的分辨率降低。这种操作具有使特征映射的输出对平移和其他
形式的变形的敏感度下降的作用。</p>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/04/06/Convolutional-Neural-Networks/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <ul class="pager">
    
    <li class="previous"><a href="/blog/page/4/">&larr; Older</a></li>
    
    <li><a href="/blog/archives">Blog Archives</a></li>
    
    <li class="next"><a href="/blog/page/2/">Newer &rarr;</a></li>
    
  </ul>
</div>
<aside class="sidebar-nav span3">
  
    <section>
  <h2>Categories</h2>
    <ul id="category-list">
		<li><a href='/blog/categories/assp'>ASSP (15)</a></li><li><a href='/blog/categories/engineering'>Engineering (4)</a></li><li><a href='/blog/categories/intelligence'>Intelligence (4)</a></li><li><a href='/blog/categories/life'>Life (11)</a></li><li><a href='/blog/categories/linux'>Linux (3)</a></li><li><a href='/blog/categories/math'>Math (5)</a></li><li><a href='/blog/categories/prml'>PRML (12)</a></li><li><a href='/blog/categories/program'>Program (29)</a></li><li><a href='/blog/categories/technics'>Technics (7)</a></li><li><a href='/blog/categories/view'>View (7)</a></li>
	</ul>
</section>
<section>
  <h2>Tags</h2>
  <ul class="tag-cloud">
	<a style="font-size: 93%" href="/blog/tags/alize/">Alize</a>
<a style="font-size: 137%" href="/blog/tags/audio/">Audio</a>
<a style="font-size: 146%" href="/blog/tags/c/">C</a>
<a style="font-size: 93%" href="/blog/tags/convex/">Convex</a>
<a style="font-size: 112%" href="/blog/tags/deeplearning/">DeepLearning</a>
<a style="font-size: 93%" href="/blog/tags/htk/">HTK</a>
<a style="font-size: 146%" href="/blog/tags/life/">Life</a>
<a style="font-size: 93%" href="/blog/tags/love/">Love</a>
<a style="font-size: 93%" href="/blog/tags/machinelearning/">MachineLearning</a>
<a style="font-size: 159%" href="/blog/tags/neuralnetworks/">NeuralNetworks</a>
<a style="font-size: 93%" href="/blog/tags/nuance/">Nuance</a>
<a style="font-size: 153%" href="/blog/tags/php/">PHP</a>
<a style="font-size: 93%" href="/blog/tags/perceptron/">Perceptron</a>
<a style="font-size: 112%" href="/blog/tags/prim/">Prim</a>
<a style="font-size: 153%" href="/blog/tags/programtest/">ProgramTest</a>
<a style="font-size: 93%" href="/blog/tags/programing/">Programing</a>
<a style="font-size: 146%" href="/blog/tags/python/">Python</a>
<a style="font-size: 126%" href="/blog/tags/quicksort/">QuickSort</a>
<a style="font-size: 93%" href="/blog/tags/rbm/">RBM</a>
<a style="font-size: 93%" href="/blog/tags/speakerrecognition/">SpeakerRecognition</a>
<a style="font-size: 112%" href="/blog/tags/speech/">Speech</a>
<a style="font-size: 93%" href="/blog/tags/uml/">UML</a>
<a style="font-size: 93%" href="/blog/tags/vpr/">VPR</a>
<a style="font-size: 112%" href="/blog/tags/web/">Web</a>
<a style="font-size: 165%" href="/blog/tags/zju/">ZJU</a>

  </ul>
</section><section>
  <h2>Recent Comments</h2>
  <script type="text/javascript" src="http://ibillxia.disqus.com/recent_comments_widget.js?num_items=5&hide_avatars=0&avatar_size=32&excerpt_length=22"></script>
  <a href="http://disqus.com/">Powered by Disqus</a>
</section>

<section>
  <h2>Sina Weibo</h2>
  <ul id="weibo">
	<iframe 
		width="100%" 
		height="550" 
		class="share_self"  
		frameborder="0" 
		scrolling="no" 
		src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=2&ptype=1&speed=0&skin=1&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=2704795533&verifier=9551ab13&dpc=1">
	</iframe>
  </ul>
</section>

<section>
	<h2>Reading List</h2>
	<ul>
		<script type="text/javascript" src="http://www.douban.com/service/badge/65527470/?show=collection&amp;n=12&amp;columns=3" ></script>
	</ul>
</section>
<section>
  <h2>Copyleft</h2>
  <p align="center"><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png"></a></p>
  <p>Except where otherwise noted, content on this site is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US">Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a></p>
</section>
  
</aside>

    </div>
  </div>
  <footer role="contentinfo" class="page-footer"><p id = "back-top">
	<a href="#top"><span></span>Back to Top</a>
</p>
<hr>
<p>
  Copyright &copy; 2009 - 2014 - <a href="http://about.me/ibillxia">Bill Xia</a> -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> - Theme by <a href="http://twitter.github.com/bootstrap/">Twitter Bootstrap</a> </span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'ibillxia';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
